# Sele√ß√£o de Features com Algoritmo Gen√©tico

![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)
![Numpy](https://img.shields.io/badge/Numpy-1.21%2B-orange.svg)

## üìù Descri√ß√£o do Projeto

Este projeto √© uma implementa√ß√£o em Python de um **Algoritmo Gen√©tico (AG)**, uma meta-heur√≠stica de otimiza√ß√£o inspirada na teoria da evolu√ß√£o de Charles Darwin. O c√≥digo √© uma demonstra√ß√£o pr√°tica dos conceitos apresentados em pesquisas sobre o tema, como o artigo *"[A systematic literature review of the Genetic Algorithm based Feature Selection for machine learning](https://www.sciencedirect.com/science/article/abs/pii/S0167404821002728)"*.

O objetivo do algoritmo √© encontrar o **subconjunto ideal de features** (caracter√≠sticas) em um conjunto de dados, buscando um equil√≠brio entre dois objetivos conflitantes:
1.  **Maximizar a performance** de um modelo de Machine Learning (simulada nesta implementa√ß√£o).
2.  **Minimizar o n√∫mero de features** utilizadas, promovendo modelos mais simples, r√°pidos e menos propensos a overfitting.

Cada "indiv√≠duo" na popula√ß√£o do AG representa uma poss√≠vel solu√ß√£o, onde um vetor bin√°rio (cromossomo) indica a aus√™ncia (0) ou presen√ßa (1) de uma feature.

## üß¨ Componentes do Algoritmo Gen√©tico

1.  **Inicializa√ß√£o:** Uma popula√ß√£o de solu√ß√µes (vetores bin√°rios) √© criada aleatoriamente.
2.  **Avalia√ß√£o (Fitness):** Cada solu√ß√£o √© avaliada por uma fun√ß√£o que calcula seu "valor". A f√≥rmula busca minimizar o resultado de `(1 - Acur√°cia) + Penalidade`.
    * A **Acur√°cia** √© **simulada** para fins did√°ticos.
    * A **Penalidade** aumenta proporcionalmente ao n√∫mero de features selecionadas.
3.  **Sele√ß√£o (Torneio):** Indiv√≠duos com melhor fitness (menor valor) s√£o selecionados com maior probabilidade para se tornarem "pais" da pr√≥xima gera√ß√£o.
4.  **Crossover (Recombina√ß√£o Uniforme):** Os "pais" trocam material gen√©tico para criar "filhos", combinando caracter√≠sticas das solu√ß√µes existentes.
5.  **Muta√ß√£o (Bit-Flip):** Uma pequena chance de muta√ß√£o (inverter um bit) √© aplicada aos filhos para introduzir diversidade e explorar novas √°reas do espa√ßo de busca.
6.  **Elitismo:** Os melhores indiv√≠duos da gera√ß√£o atual s√£o transferidos diretamente para a pr√≥xima, garantindo que o progresso alcan√ßado nunca seja perdido.
7.  **Repeti√ß√£o:** O ciclo se repete por um n√∫mero definido de gera√ß√µes, evoluindo a popula√ß√£o em dire√ß√£o a uma solu√ß√£o cada vez melhor.

## üõ†Ô∏è Tecnologias e Bibliotecas

* **Linguagem:** Python 3
* **Bibliotecas Principais:**
    * **Numpy:** Para opera√ß√µes num√©ricas eficientes e manipula√ß√£o de arrays.

## üìÅ Estrutura do Projeto

O projeto √© contido em um √∫nico script para facilitar a execu√ß√£o e o entendimento.

```bash
selecao-features-ag/
‚îú‚îÄ‚îÄ main.py      # Script principal com toda a l√≥gica do AG
‚îî‚îÄ‚îÄ README.md    # Esta documenta√ß√£o
```

## üöÄ Como Rodar o Projeto

#### **Pr√©-requisitos**

* **Python** (vers√£o 3.8 ou superior)
* **pip** (gerenciador de pacotes do Python)

#### **1. Configura√ß√£o do Ambiente**

√â recomendado o uso de um ambiente virtual (`venv`) para isolar as depend√™ncias.

```bash
# Crie um ambiente virtual
python -m venv venv

# Ative o ambiente virtual
# No Windows:
.\venv\Scripts\activate
# No macOS/Linux:
source venv/bin/activate

# Instale as depend√™ncias
pip install numpy
```

#### **2. Executando a Aplica√ß√£o**

Este projeto **n√£o requer um arquivo de dados externo**, pois opera com um dataset e uma fun√ß√£o de fitness simulados para focar na mec√¢nica do algoritmo.

Com o ambiente ativado, execute o seguinte comando no terminal:

```bash
python main.py
```

#### **Sa√≠da Esperada**

Ao final da execu√ß√£o, o terminal exibir√° um resultado similar a este:

```
Iniciando otimiza√ß√£o...
Gera√ß√£o 10/50 | Melhor Fitness: 0.2815 | Features: 8
Gera√ß√£o 20/50 | Melhor Fitness: 0.2601 | Features: 7
Gera√ß√£o 30/50 | Melhor Fitness: 0.2455 | Features: 5
Gera√ß√£o 40/50 | Melhor Fitness: 0.2455 | Features: 5
Gera√ß√£o 50/50 | Melhor Fitness: 0.2455 | Features: 5

--- Resultado Final ---
Melhor subconjunto de features: [0 1 0 0 1 0 ... 1 0 1 0 1]
N√∫mero de features selecionadas: 5
Fitness final: 0.2455
```

## üîß De Simula√ß√£o para Aplica√ß√£o Real

Para adaptar este projeto a um problema real, a principal mudan√ßa ocorre na fun√ß√£o `calcular_fitness`. Em vez de simular a acur√°cia, voc√™ deve trein√°-la e avali√°-la usando um modelo de Machine Learning real.

A l√≥gica seria a seguinte:

```python
# Exemplo de como a fun√ß√£o fitness seria em um caso real
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

def calcular_fitness_real(individuo, dataset, labels):
    indices_ativos = [i for i, bit in enumerate(individuo) if bit == 1]
    
    if len(indices_ativos) == 0:
        return float('inf')

    # 1. Selecionar apenas as features ativas
    X_selecionado = dataset[:, indices_ativos]

    # 2. Dividir os dados
    X_train, X_test, y_train, y_test = train_test_split(X_selecionado, labels, test_size=0.3, stratify=labels)

    # 3. Treinar e avaliar o modelo
    model = RandomForestClassifier(n_estimators=50)
    model.fit(X_train, y_train)
    acuracia_real = accuracy_score(y_test, model.predict(X_test))

    # 4. Calcular o fitness com a acur√°cia real
    proporcao_usada = len(indices_ativos) / len(individuo)
    penalidade = proporcao_usada * 0.2
    fitness = (1 - acuracia_real) + penalidade
    
    return fitness
```